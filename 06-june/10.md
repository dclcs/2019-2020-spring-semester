# June 10^th^, 2020

## VR's Video

今日说法：VR 视觉显示技术概述。

### Requirements

* 真实感（Reality）
* 沉浸感（Immersion）
* 低延迟（Low Delay）

当然…这些要求都不是绝对的。

和真实物理场景对比，总会稍微有些逊色。

比较实际、确切的要求是：

* 和真实物理场景对比，几乎无法区分
* 用户不会感知到身体不适和明显的负荷
* 成本低至可普及使用

### Benchmark

为了评估一个 VR 系统的视觉显示效果，我们提出下列评价标准：

* 视场（**F**ield **o**f **V**ision）
* 分辨率（Resolution）
* 亮度（Brightness）
* 色彩对比度（Contrast）
* 刷新频率（Refresh Frequency）

> 这些基本上就是一般显示器的评价标准加上 FoV。

除此之外，还有一些人体工程学的评估标准：

* 重量
* 佩戴舒适度

还有一些比较通用的外设评估标准：

* 安全性
* 可靠性
* 价格

### Category

* 沉浸式（Immerse）
  * Hook 所有的外界输入
  * 展示一个完全虚拟的场景
* 非沉浸式（Non-Immerse）
  * 仅仅展示一部分真实感环境
  * 和真实世界混合共存

### Modules

VR 的视觉接口…包含哪些模块？

其至少包含以下模块：

#### Vision Displaying System

视觉显示表面，也就是产生「光」的源头。

根据 Core Processor 的需要，产生特殊的光学模式并将其投影到用户的视网膜上。

> 这一模块有时也包含一些辅助光学系统。

常见的显示系统包括：

* CRT / LCD 显示器
* 投影幕
* HMD 的头盔显示器
* 类似 HoloLens 的激光全息投影表面
* LightField 光场显示

当然，如果要提供立体视觉，就不得不借助一些手段来分别提供左、右眼的信号。可能的实现方法包括：

* 立体眼镜
* 头盔式
* 被动式
* 自由式
* CAVE 沉浸式

#### Signal Generating System

信号产生系统。也就是决定应该展示什么样的画面，并将其电子编码发送给 Vision Displaying System。

它可能是：

* 真实场景摄像设备
* 存储图像的录像机
* 生成真实感图形的计算机

#### Tracking System

为了制造「沉浸式」的体验，系统需要采集观察者目前的观察方向、位置来改变渲染内容。

这一信息就由 Tracking System 采集并发送给 Singal Generating System。

## VR's Audio

VR 系统对于听觉显示的要求…相对而言没有那么严格。

因为人的感知主要集中在视觉和听觉；但在此之中，视觉的占比又远远大于听觉。

### Requirements

* 立体声支持
  * （至少要能给两只耳朵不同的声音效果吧）
* 实时交互
  * 用户快速转动听觉方向、移动听觉位置时，能否迅速进行波形计算
* 噪声支持
  * 提供一些背景噪声，增加一些真实感
  * 如果没有的话，就会感觉很虚假了

### Modules

#### Audio Generating Devices

最基础的发声设备。

> 当然得有了，否则声音从哪儿来呢？

最常见的，普通的耳机就可以做到独立双耳的声音产生。而且大部分耳机都具有降噪功能，隔绝了真实世界的声音能够使得模拟结果更为真实。

> 只不过因为需要戴在头上，因此增加了负担。

无接触式的呢，环绕立体声音响同时可以产生真实震动，让全身都可以感知到，大概是比较真实吧。

> 只不过相比耳机容易受干扰。

#### Spacial Locating System

空间定位。

要模拟用户在虚拟空间中能听到的真实效果，就必须获知用户的位置和方向才可以。Spacial Locating 模块就是负责采集这个数据的。

这个和 Video 里的 Tracking System 是一回事；反正就是确认六个自由度嘛。

#### Audio Synthesiser

把所有的声音（包括噪声）混合在一起，交给 Audio Generating Devices 发声。

声音主要分为三种：

* 直达声
  * 直接传播到听众左右耳的声音
* 反射声
  * 声音在室内表面经过仅 1 次反射之后传入耳朵的声音
* 混响声
  * 声音经过多次反射之后（已经非常微弱了！）的一些微弱噪音

> 耳朵呢，没有眼睛那么聪明，比较好骗。
>
> 只要传到两只耳朵里的声音的「音量」和「时机」刚好类似，就能骗过耳朵啦。
>
> 相比眼睛（可以说是每只眼睛都独立是二维的数据采集源）来说，每只耳朵只能算是一维的数据采集源。

## Q & A

### Question

CAVE 的立体视觉是如何产生的？

### Answer

这也是个递归简称（很好，非常 GNU）：

CAVE = **C**AVE **A**utomatic **V**irtual **E**nvironment

用三个或以上的面来组成高度沉浸式的虚拟演示环境。

简单说，就是像一个「洞穴」（Cave）一样在四周显示画面，并根据目前观察者的所在位置和方向来调整显示画面，以实现立体感的模拟。

能覆盖观察者的所有视野，而且不需要额外的配置，可以实现 6 通道自由度的虚拟现实效果。

但是，假如这里我们只是在六面墙上放上普通的平面显示器，依然无法产生立体效果。

因此，我们有两种策略来解决这个问题：

A）要么让用户带上立体眼镜，给两眼展示不同的内容。

B）用镜面反射的原理产生裸眼 3D 视觉。

A）方案仍然要求额外的头戴式设备，而且这样还不如直接用头盔。

B）方案完全无需人携带外设，如果更新速度足够快，甚至可以实现以假乱真的效果。

